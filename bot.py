import os
import asyncio
import logging
from datetime import datetime
from typing import List, Dict, Optional
import aiohttp
from bs4 import BeautifulSoup
from telegram import Bot
import re

logging.basicConfig(
    format='%(asctime)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏
BOT_TOKEN = os.getenv('BOT_TOKEN')
CHANNEL_ID = os.getenv('CHANNEL_ID', "-1003812789640")
MESSAGE_THREAD_ID = int(os.getenv('MESSAGE_THREAD_ID', '4'))

# Telegram –∫–∞–Ω–∞–ª—ã —Å –¥–∞–π–¥–∂–µ—Å—Ç–∞–º–∏ —Å–æ–±—ã—Ç–∏–π
TELEGRAM_CHANNELS = [
    {"username": "startup_course_com", "name": "Startup Course"},
    {"username": "astanahub_events", "name": "Astana Hub Events"},
    {"username": "digitalbusinesskz", "name": "Digital Business KZ"},
    {"username": "vcinsightskz", "name": "VC Insights KZ"},
    {"username": "startupalmaty", "name": "Startup Almaty"},
]

# –ú–µ—Å—è—Ü—ã
MONTHS_RU = {
    '—è–Ω–≤–∞—Ä—è': 1, '—Ñ–µ–≤—Ä–∞–ª—è': 2, '–º–∞—Ä—Ç–∞': 3, '–∞–ø—Ä–µ–ª—è': 4,
    '–º–∞—è': 5, '–∏—é–Ω—è': 6, '–∏—é–ª—è': 7, '–∞–≤–≥—É—Å—Ç–∞': 8,
    '—Å–µ–Ω—Ç—è–±—Ä—è': 9, '–æ–∫—Ç—è–±—Ä—è': 10, '–Ω–æ—è–±—Ä—è': 11, '–¥–µ–∫–∞–±—Ä—è': 12
}


def parse_date_str(date_str: str) -> Optional[datetime]:
    """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å —Å—Ç—Ä–æ–∫—É –¥–∞—Ç—ã –≤ datetime"""
    try:
        text = date_str.lower().strip()

        # "14-15.02" –∏–ª–∏ "14-15.02.2026"
        match = re.search(r'(\d{1,2})[-‚Äì](\d{1,2})\.(\d{2})(?:\.(\d{4}))?', text)
        if match:
            day = int(match.group(2))
            month = int(match.group(3))
            year = int(match.group(4)) if match.group(4) else datetime.now().year
            return datetime(year, month, day)

        # "12.02" –∏–ª–∏ "12.02.2026"
        match = re.search(r'(\d{1,2})\.(\d{2})(?:\.(\d{4}))?', text)
        if match:
            day = int(match.group(1))
            month = int(match.group(2))
            year = int(match.group(3)) if match.group(3) else datetime.now().year
            return datetime(year, month, day)

        # "14-15 —Ñ–µ–≤—Ä–∞–ª—è 2026"
        match = re.search(r'(\d{1,2})[-‚Äì](\d{1,2})\s+([–∞-—è]+)(?:\s+(\d{4}))?', text)
        if match:
            day = int(match.group(2))
            month = MONTHS_RU.get(match.group(3), 0)
            year = int(match.group(4)) if match.group(4) else datetime.now().year
            if month:
                return datetime(year, month, day)

        # "14 —Ñ–µ–≤—Ä–∞–ª—è 2026"
        match = re.search(r'(\d{1,2})\s+([–∞-—è]+)(?:\s+(\d{4}))?', text)
        if match:
            day = int(match.group(1))
            month = MONTHS_RU.get(match.group(2), 0)
            year = int(match.group(3)) if match.group(3) else datetime.now().year
            if month:
                return datetime(year, month, day)

    except Exception as e:
        logger.debug(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–∞—Ç—ã '{date_str}': {e}")

    return None


def is_future(date_str: str) -> bool:
    """–°–æ–±—ã—Ç–∏–µ –≤ –±—É–¥—É—â–µ–º? –°—Ç—Ä–æ–≥–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞"""
    if not date_str:
        return False  # –ï—Å–ª–∏ –¥–∞—Ç–∞ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–∞ - –ù–ï –±–µ—Ä–µ–º (–±—ã–ª–æ True, —Å—Ç–∞–ª–æ False)

    dt = parse_date_str(date_str)
    if not dt:
        return False  # –ï—Å–ª–∏ –Ω–µ —Å–º–æ–≥–ª–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –¥–∞—Ç—É - –ù–ï –±–µ—Ä–µ–º

    return dt.date() > datetime.now().date()  # –°—Ç—Ä–æ–≥–æ –±–æ–ª—å—à–µ (–Ω–µ —Å–µ–≥–æ–¥–Ω—è, –∞ –∑–∞–≤—Ç—Ä–∞+)


def extract_events_from_digest(text: str, source_link: str, source_name: str) -> List[Dict]:
    """
    –†–∞–∑–±–∏—Ç—å –¥–∞–π–¥–∂–µ—Å—Ç –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è.
    –ü—Ä–∏–º–µ—Ä —Å—Ç—Ä–æ–∫–∏: "12.02 –≤ 10:00 ‚òÅÔ∏è –ö–æ–Ω—Ñ–µ—Ä–µ–Ω—Ü–∏—è PRO-DATA CLOUD @ Holiday Inn t.me/..."
    """
    events = []

    # –ü–∞—Ç—Ç–µ—Ä–Ω —Å—Ç—Ä–æ–∫–∏ —Å–æ–±—ã—Ç–∏—è:
    # "12.02 –≤ 10:00" –∏–ª–∏ "14-15.02 –≤ 10:00" + —Ç–µ–∫—Å—Ç + —Å—Å—ã–ª–∫–∞
    event_pattern = re.compile(
        r'(\d{1,2}[-‚Äì]?\d{0,2}[.\s]\d{2}(?:\.\d{4})?)\s*(?:–≤\s*(\d{1,2}:\d{2}))?\s*([^\n]+?)(?:\s+((?:https?://|t\.me/)\S+))?(?:\n|$)',
        re.MULTILINE
    )

    lines = text.split('\n')

    i = 0
    while i < len(lines):
        line = lines[i].strip()
        if not line:
            i += 1
            continue

        # –ò—â–µ–º —Å—Ç—Ä–æ–∫—É —Å –¥–∞—Ç–æ–π –≤ –Ω–∞—á–∞–ª–µ (–ø—Ä–∏–∑–Ω–∞–∫ —Å–æ–±—ã—Ç–∏—è –≤ –¥–∞–π–¥–∂–µ—Å—Ç–µ)
        date_match = re.match(
            r'^(\d{1,2}[-‚Äì]?\d{0,2}[.\s]\d{2}(?:\.\d{4})?)\s*(?:–≤\s*(\d{1,2}:\d{2}))?',
            line
        )

        if date_match:
            date_str = date_match.group(1).replace(' ', '.')
            time_str = date_match.group(2)

            # –£–±–∏—Ä–∞–µ–º –¥–∞—Ç—É –∏ –≤—Ä–µ–º—è –∏–∑ —Å—Ç—Ä–æ–∫–∏ - –æ—Å—Ç–∞–µ—Ç—Å—è –æ–ø–∏—Å–∞–Ω–∏–µ
            event_text = line[date_match.end():].strip()

            # –£–±–∏—Ä–∞–µ–º —ç–º–æ–¥–∑–∏ –≤ –Ω–∞—á–∞–ª–µ
            event_text = re.sub(r'^[\U00010000-\U0010ffff\u2600-\u27ff\s]+', '', event_text).strip()

            # –ò—â–µ–º —Å—Å—ã–ª–∫—É –≤ —ç—Ç–æ–π –∏–ª–∏ —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç—Ä–æ–∫–µ
            link = None
            link_match = re.search(r'((?:https?://|t\.me/)\S+)', event_text)
            if link_match:
                link = link_match.group(1)
                if not link.startswith('http'):
                    link = 'https://' + link
                event_text = event_text[:link_match.start()].strip()
            elif i + 1 < len(lines):
                next_line = lines[i + 1].strip()
                link_match = re.search(r'((?:https?://|t\.me/)\S+)', next_line)
                if link_match:
                    link = link_match.group(1)
                    if not link.startswith('http'):
                        link = 'https://' + link

            # –ò—â–µ–º –º–µ—Å—Ç–æ "@"
            venue = None
            venue_match = re.search(r'@\s+([^@\n]+?)(?:\s+(?:https?://|t\.me/)|\s*$)', event_text)
            if venue_match:
                venue = venue_match.group(1).strip()
                event_text = event_text[:venue_match.start()].strip()

            if not event_text or len(event_text) < 5:
                i += 1
                continue

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –¥–∞—Ç–∞ –≤ –±—É–¥—É—â–µ–º (—Å—Ç—Ä–æ–≥–æ)
            if not is_future(date_str):
                logger.info(f"‚è≠Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–æ—à–µ–¥—à–µ–µ: {event_text[:40]} ({date_str})")
                i += 1
                continue

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–µ—Å—Ç–æ
            location = venue or extract_location(event_text)

            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –µ—Å–ª–∏ –Ω–µ—Ç –º–µ—Å—Ç–∞
            if not location:
                logger.info(f"‚è≠Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –±–µ–∑ –º–µ—Å—Ç–∞: {event_text[:40]}")
                i += 1
                continue

            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–∞—Ç—É –∫—Ä–∞—Å–∏–≤–æ
            formatted_date = format_date(date_str, time_str)

            events.append({
                'title': event_text[:150],
                'date': formatted_date,
                'date_raw': date_str,
                'venue': location,
                'link': link or source_link,
                'source': source_name,
                'image_url': None
            })

        i += 1

    return events


def format_date(date_str: str, time_str: Optional[str] = None) -> str:
    """–ö—Ä–∞—Å–∏–≤–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å –¥–∞—Ç—É"""
    months_names = {
        1: '—è–Ω–≤–∞—Ä—è', 2: '—Ñ–µ–≤—Ä–∞–ª—è', 3: '–º–∞—Ä—Ç–∞', 4: '–∞–ø—Ä–µ–ª—è',
        5: '–º–∞—è', 6: '–∏—é–Ω—è', 7: '–∏—é–ª—è', 8: '–∞–≤–≥—É—Å—Ç–∞',
        9: '—Å–µ–Ω—Ç—è–±—Ä—è', 10: '–æ–∫—Ç—è–±—Ä—è', 11: '–Ω–æ—è–±—Ä—è', 12: '–¥–µ–∫–∞–±—Ä—è'
    }

    dt = parse_date_str(date_str)
    if dt:
        result = f"{dt.day} {months_names[dt.month]} {dt.year}"
        if time_str:
            result += f", {time_str}"
        return result

    return date_str


def extract_location(text: str) -> Optional[str]:
    """–ò–∑–≤–ª–µ—á—å –≥–æ—Ä–æ–¥"""
    cities = {
        '–ê–ª–º–∞—Ç—ã': '–ê–ª–º–∞—Ç—ã', '–ê—Å—Ç–∞–Ω–∞': '–ê—Å—Ç–∞–Ω–∞', '–ù—É—Ä-–°—É–ª—Ç–∞–Ω': '–ê—Å—Ç–∞–Ω–∞',
        '–®—ã–º–∫–µ–Ω—Ç': '–®—ã–º–∫–µ–Ω—Ç', '–û–Ω–ª–∞–π–Ω': '–û–Ω–ª–∞–π–Ω', '–û–ù–õ–ê–ô–ù': '–û–Ω–ª–∞–π–Ω',
        'Online': '–û–Ω–ª–∞–π–Ω', 'ZOOM': '–û–Ω–ª–∞–π–Ω (Zoom)', '–¢–∞—à–∫–µ–Ω—Ç': '–¢–∞—à–∫–µ–Ω—Ç'
    }
    for key, value in cities.items():
        if key.lower() in text.lower():
            return value
    return None


def format_post(event: Dict) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å –æ–¥–∏–Ω –ø–æ—Å—Ç"""
    lines = []

    # –ó–∞–≥–æ–ª–æ–≤–æ–∫
    title = event['title']
    if len(title) > 120:
        title = title[:117] + '...'
    lines.append(f"üéØ <b>{title}</b>")
    lines.append("")

    # –î–∞—Ç–∞
    if event.get('date'):
        lines.append(f"üìÖ {event['date']}")

    # –ú–µ—Å—Ç–æ
    location = event.get('venue') or extract_location(event['title'])
    if location:
        lines.append(f"üìç {location}")

    # –û—Ä–≥–∞–Ω–∏–∑–∞—Ç–æ—Ä
    lines.append(f"üìå {event['source']}")

    # –°—Å—ã–ª–∫–∞
    lines.append("")
    lines.append(f"üîó <a href='{event['link']}'>–ü–æ–¥—Ä–æ–±–Ω–µ–µ ‚Üí</a>")

    return "\n".join(lines)


class DigestParser:
    def __init__(self):
        self.session = None
        self.posted_cache = set()

    async def get_session(self):
        if not self.session:
            self.session = aiohttp.ClientSession(
                headers={'User-Agent': 'Mozilla/5.0'}
            )
        return self.session

    async def close(self):
        if self.session:
            await self.session.close()

    async def fetch(self, url: str) -> str:
        try:
            session = await self.get_session()
            async with session.get(url, timeout=15) as resp:
                return await resp.text() if resp.status == 200 else ""
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {url}: {e}")
            return ""

    async def parse_telegram(self, channel: Dict) -> List[Dict]:
        """–ü–∞—Ä—Å–∏–Ω–≥ Telegram –∫–∞–Ω–∞–ª–∞ - –∫–∞–∂–¥–æ–µ —Å–æ–±—ã—Ç–∏–µ –æ—Ç–¥–µ–ª—å–Ω–æ"""
        try:
            url = f"https://t.me/s/{channel['username']}"
            html = await self.fetch(url)
            if not html:
                return []

            soup = BeautifulSoup(html, 'html.parser')
            all_events = []

            for msg in soup.find_all('div', class_='tgme_widget_message'):
                try:
                    text_div = msg.find('div', class_='tgme_widget_message_text')
                    if not text_div:
                        continue

                    text = text_div.get_text(strip=True, separator='\n')
                    if len(text) < 20:
                        continue

                    # –°—Å—ã–ª–∫–∞ –Ω–∞ –ø–æ—Å—Ç
                    link_elem = msg.find('a', class_='tgme_widget_message_date')
                    post_link = link_elem['href'] if link_elem else f"https://t.me/{channel['username']}"

                    if post_link in self.posted_cache:
                        continue

                    # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∫—ç—à –°–†–ê–ó–£ —á—Ç–æ–±—ã –Ω–µ –¥—É–±–ª–∏—Ä–æ–≤–∞—Ç—å
                    self.posted_cache.add(post_link)

                    # –ö–∞—Ä—Ç–∏–Ω–∫–∞ –ø–æ—Å—Ç–∞
                    image_url = None
                    img_div = msg.find('a', class_='tgme_widget_message_photo_wrap')
                    if img_div:
                        style = img_div.get('style', '')
                        img_match = re.search(r"url\('([^']+)'\)", style)
                        if img_match:
                            image_url = img_match.group(1)

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º: —ç—Ç–æ –¥–∞–π–¥–∂–µ—Å—Ç (—Å–ø–∏—Å–æ–∫ —Å–æ–±—ã—Ç–∏–π)?
                    is_digest = bool(re.search(
                        r'\d{1,2}[.\-]\d{2}\s+(?:–≤\s+)?\d{1,2}:\d{2}',
                        text
                    ))

                    if is_digest:
                        # –†–∞–∑–±–∏–≤–∞–µ–º –¥–∞–π–¥–∂–µ—Å—Ç –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è
                        events = extract_events_from_digest(text, post_link, channel['name'])
                        logger.info(f"üìã –î–∞–π–¥–∂–µ—Å—Ç –≤ {channel['name']}: –Ω–∞–π–¥–µ–Ω–æ {len(events)} —Å–æ–±—ã—Ç–∏–π")
                        for event in events:
                            event['image_url'] = image_url
                            all_events.append(event)
                    else:
                        # –û–±—ã—á–Ω—ã–π –ø–æ—Å—Ç - –æ–¥–Ω–æ —Å–æ–±—ã—Ç–∏–µ
                        event_kw = ['–∫–æ–Ω—Ñ–µ—Ä–µ–Ω—Ü–∏—è', 'meetup', '—Ö–∞–∫–∞—Ç–æ–Ω', 'workshop',
                                    '–≤–µ–±–∏–Ω–∞—Ä', 'pitch', '–∞–∫—Å–µ–ª–µ—Ä–∞—Ç–æ—Ä', '–≤–æ—Ä–∫—à–æ–ø',
                                    '–º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–µ', 'event', '—Ç—Ä–µ–Ω–∏–Ω–≥', '–∫–æ–Ω–∫—É—Ä—Å']

                        if not any(kw in text.lower() for kw in event_kw):
                            continue

                        date_str = None
                        date_match = re.search(
                            r'(\d{1,2}[-‚Äì]?\d{0,2}[.\s]\d{2}(?:\.\d{4})?)',
                            text
                        )
                        if date_match:
                            date_str = date_match.group(1)

                        time_match = re.search(r'–≤\s*(\d{1,2}:\d{2})', text)
                        time_str = time_match.group(1) if time_match else None

                        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –µ—Å–ª–∏ –Ω–µ—Ç –¥–∞—Ç—ã
                        if not date_str:
                            logger.info(f"‚è≠Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–æ—Å—Ç –±–µ–∑ –¥–∞—Ç—ã")
                            continue

                        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–æ—à–µ–¥—à–∏–µ
                        if not is_future(date_str):
                            logger.info(f"‚è≠Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–æ—à–µ–¥—à–µ–µ ({date_str})")
                            continue

                        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –µ—Å–ª–∏ –Ω–µ—Ç –º–µ—Å—Ç–∞
                        location = extract_location(text)
                        if not location:
                            logger.info(f"‚è≠Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–æ—Å—Ç –±–µ–∑ –º–µ—Å—Ç–∞ –ø—Ä–æ–≤–µ–¥–µ–Ω–∏—è")
                            continue

                        formatted_date = format_date(date_str, time_str)

                        # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 100 —Å–∏–º–≤–æ–ª–æ–≤ –∫–∞–∫ –∑–∞–≥–æ–ª–æ–≤–æ–∫
                        title = text.split('\n')[0][:150]

                        all_events.append({
                            'title': title,
                            'date': formatted_date,
                            'date_raw': date_str,
                            'venue': location,
                            'link': post_link,
                            'source': channel['name'],
                            'image_url': image_url
                        })

                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")
                    continue

            return all_events

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ TG {channel['name']}: {e}")
            return []

    async def get_all_events(self) -> List[Dict]:
        all_events = []

        for channel in TELEGRAM_CHANNELS:
            events = await self.parse_telegram(channel)
            all_events.extend(events)
            if events:
                logger.info(f"‚úÖ {channel['name']}: {len(events)} —Å–æ–±—ã—Ç–∏–π")

        return all_events


async def main():
    logger.info("üöÄ –ò—â–µ–º –ø—Ä–µ–¥—Å—Ç–æ—è—â–∏–µ —Å–æ–±—ã—Ç–∏—è...")

    if not BOT_TOKEN:
        logger.error("‚ùå BOT_TOKEN –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω!")
        return

    parser = DigestParser()
    bot = Bot(token=BOT_TOKEN)

    try:
        events = await parser.get_all_events()

        if not events:
            logger.warning("‚ö†Ô∏è –°–æ–±—ã—Ç–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
            return

        # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
        unique_events = []
        seen = set()
        for event in events:
            key = event['title'][:50]
            if key not in seen:
                unique_events.append(event)
                seen.add(key)

        logger.info(f"üìä –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–æ–±—ã—Ç–∏–π: {len(unique_events)}")

        posted = 0
        for event in unique_events[:15]:
            try:
                text = format_post(event)

                if event.get('image_url'):
                    try:
                        await bot.send_photo(
                            chat_id=CHANNEL_ID,
                            message_thread_id=MESSAGE_THREAD_ID,
                            photo=event['image_url'],
                            caption=text,
                            parse_mode='HTML'
                        )
                    except:
                        await bot.send_message(
                            chat_id=CHANNEL_ID,
                            message_thread_id=MESSAGE_THREAD_ID,
                            text=text,
                            parse_mode='HTML',
                            disable_web_page_preview=True  # –£–±–∏—Ä–∞–µ–º –∑–µ–ª–µ–Ω—É—é —Ä–∞–º–∫—É
                        )
                else:
                    await bot.send_message(
                        chat_id=CHANNEL_ID,
                        message_thread_id=MESSAGE_THREAD_ID,
                        text=text,
                        parse_mode='HTML',
                        disable_web_page_preview=True  # –£–±–∏—Ä–∞–µ–º –∑–µ–ª–µ–Ω—É—é —Ä–∞–º–∫—É
                    )

                posted += 1
                logger.info(f"‚úÖ ({posted}) {event['title'][:50]}")
                await asyncio.sleep(2)

            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞: {e}")

        logger.info(f"‚úÖ –ì–æ—Ç–æ–≤–æ! –û–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–æ: {posted} —Å–æ–±—ã—Ç–∏–π")

    finally:
        await parser.close()


if __name__ == '__main__':
    asyncio.run(main())